litellm_settings:
  drop_params: True

model_list:
  - model_name: gpt-3.5-turbo # model alias
    litellm_params: # actual params for litellm.completion()
      model: "replicate/meta/llama-2-70b-chat:02e509c789964a7ea8736978a43525956ef40397be9033abf9fd2badfe68c9e3" 
      initial_prompt_value: "\n"
      roles: {"system":{"pre_message":"[INST] <<SYS>>\n","post_message":"\n<</SYS>>\n\n"}, "assistant":{"pre_message":"\n","post_message":"</s>\n"}, "user":{"pre_message":"[INST]","post_message":"[/INST]"}}
      final_prompt_value: "\n"
      max_tokens: 4096
      supports_system_prompt: true